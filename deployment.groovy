//The jenkins sshagent plugin does not work well inside a docker container.
//This implementation would rely only on shell and standard ssh tool to support
//it thus it would be much more stable and easy to debug rather than depending
//on jenkins plugin which is not working for inside container at the moment.

//To use it at the run_build_scripts function pass the argument 'ssh_key_id'
//which is the string of the jenkins ssh private key crdential store. This will
//activate this function and setup agent automatically.

def generate_prepare_ssh_agent_script() {
    stage('generate_prepare_ssh_agent_script') {
        script {
            sh '''cat <<EOF > ssh_agent_ask_pass.sh
#!/bin/sh
# Parameter \\$1 passed to the script is the prompt text
# READ Secret from STDIN and echo it
read SECRET
echo \\$SECRET
EOF
'''
            sh 'chmod 0755 ssh_agent_ask_pass.sh'
            sh '''cat <<EOF > run_ssh_agent.sh
#!/bin/bash

# If detect SSH_KEY_FILE and SSH_PASS_PHRASE then start the ssh-agent
# All next scripts can source the file .ssh-agent to access the agent

if [ "\\$SSH_KEY_FILE" != "" ]; then
    ssh-agent > .ssh-agent
    . ./.ssh-agent
    if [ "\\$SSH_PASS_PHRASE" != "" ]; then
        SSH_ASKPASS=./ssh_agent_ask_pass.sh ssh-add \\$SSH_KEY_FILE <<< "\\$SSH_PASS_PHRASE"
    else
        ssh-add \\$SSH_KEY_FILE
    fi
    cp .ssh-agent .ssh-agent.groovy
    sed -i 's/; export .*\\$//; s/echo .*\\$//; s/^SSH_/env.SSH_/; s/=/ = "/; s/\\$/"/; s/^"\\$//  ' .ssh-agent.groovy
fi
EOF
'''
            sh 'chmod +x run_ssh_agent.sh'
        }//script
    }//stage
}//end func

def generate_add_user_script(username='') {
    stage('generate_add_user_script') {
        script {
          env.my_UID = sh(returnStdout: true, script: "id -u").trim()
          env.my_GID = sh(returnStdout: true, script: "id -g").trim()
          env.DOCKER_GID = sh(returnStdout: true, script: "grep docker /etc/group | cut -f3 -d':'").trim()
          if (username != "") {
            env.my_NAME = username
            env.UPDATE_EXISTING_USER = "yes"
          } else {
            env.my_NAME = sh(returnStdout: true, script: "whoami").trim()
          }
          sh '''cat <<EOF > generate_add_user_script.sh
#!/bin/sh
if [ -f "/etc/alpine-release" ]; then
  if ! \\`grep $my_NAME /etc/passwd >/dev/null 2>&1\\`; then
	  addgroup -g $my_GID $my_NAME
	  adduser -u $my_UID -g $my_GID -D -S $my_NAME
  else
      if [ "${UPDATE_EXISTING_USER}" = "yes" ]; then
          groupmod -g $my_GID $my_NAME
          usermod -u $my_UID -g $my_GID $my_NAME
      fi
  fi
else
  if ! \\`grep $my_NAME /etc/passwd >/dev/null 2>&1\\`; then
    groupadd -g $my_GID $my_NAME
	useradd -u $my_UID -g $my_GID $my_NAME
  else
      if [ "${UPDATE_EXISTING_USER}" = "yes" ]; then
          groupmod -g $my_GID $my_NAME
          usermod -u $my_UID -g $my_GID $my_NAME
      fi
  fi
fi

if [ ! -d /home/$my_NAME ]; then
  mkdir -p /home/$my_NAME >/dev/null 2>&1 || true
  chown -R $my_NAME:$my_GID /home/$my_NAME || true
else
  if [ "${UPDATE_EXISTING_USER}" = "yes" ]; then
    chown -R $my_NAME:$my_GID /home/$my_NAME || true
  fi
fi

if [ "$DOCKER_GID" != "" ]; then
  if ! \\`grep docker /etc/group >/dev/null 2>&1\\`; then
      groupadd -g $DOCKER_GID docker
  else
      echo "WARNING - docker group exists in /etc/group file inside the container."
      sed -i "s/docker:x:[\\d]+/docker:x:$DOCKER_GID/" /etc/group
  fi
  usermod -a -G $DOCKER_GID $my_NAME
fi
EOF
'''
          sh 'chmod +x generate_add_user_script.sh'
       }//script
    }//stage
}


def generate_aws_environment() {
    stage('generate_aws_environment') {
        withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', accessKeyVariable: 'AWS_ACCESS_KEY_ID', credentialsId: "${PROFILE}", secretKeyVariable: 'AWS_SECRET_ACCESS_KEY']]) {
            withCredentials([string(credentialsId: 'GITHUB_TOKEN', variable: 'GITHUB_TOKEN')]) {
                try {
                    //Trying to parse test if ANSIBLE_VAULT_ID is defined by
                    //two means - from groovy variable scope or from env. which
                    //is generated by Jenkins while parsing the build
                    //parameters. Thus the caller can have two way to supply
                    //this var or not supply at all - then we wont generate the
                    //ansible vault related code.
                    ANSIBLE_VAULT_ID  = env.ANSIBLE_VAULT_ID ?: ANSIBLE_VAULT_ID
                    withCredentials([string(credentialsId: "${ANSIBLE_VAULT_ID}", variable: 'VAULT')]) {
                        //As we do not run code within this block, we pick up
                        //the value and push it to env value to be
                        //used in the next script shell generation
                        env.VAULT = VAULT
                    }//withCred
                }
                catch(Exception ex) {
                    println("No ANSIBLE_VAULT_ID given")
                    env.VAULT = ''
                }
            sh '''cat <<EOF > generate_aws_environment.sh
#!/bin/sh -e
mkdir -p ~/.aws

printf "[$PROFILE]
output=json
region=ap-southeast-2
" > ~/.aws/config

printf "[$PROFILE]
aws_access_key_id = ${AWS_ACCESS_KEY_ID}
aws_secret_access_key = ${AWS_SECRET_ACCESS_KEY}

" > ~/.aws/credentials

if [ "x${ROUTE53_AWS_ACCESS_KEY_ID}" != "x" ]; then
  printf "[route53admin]
aws_access_key_id = ${ROUTE53_AWS_ACCESS_KEY_ID}
aws_secret_access_key = ${ROUTE53_AWS_SECRET_ACCESS_KEY}

" >> ~/.aws/credentials

fi

if [ "${VAULT}" != "" ]; then
    VAULT_FILE=\\$(grep -Po '(?<=vault_password_file = )[^\\s]+' ansible.cfg | sed 's/~\\///')
    echo "Vault file path: ~/\\${VAULT_FILE}"
    mkdir -p \\$(dirname ~/\\${VAULT_FILE})
    echo "${VAULT}" > ~/\\${VAULT_FILE}
    chmod 0600 ~/\\${VAULT_FILE}
    echo "Vault file: "
    ls -lha ~/\\${VAULT_FILE}
fi

sed -i "s|git+ssh://git|https://${GITHUB_TOKEN}|g" requirements.yml
./ansible-common/update-galaxy.py

ls -lha ~/.aws/
echo "Completed run generate_aws_environment.sh"

EOF
'''
          sh 'chmod +x generate_aws_environment.sh'
        }//withCred github
      }//withCred AWS
    }//stage
}

def run_build_script(arg1=[:]) {
    def default_arg = [
        'docker_net_opt': '',
        'docker_default_volume_opt': "--mount src=jenkins_home,target=$JENKINS_HOME",
        'docker_volume_opt': '',
        'docker_entrypoint_opt': '',
        'docker_args_opt': '',
        'docker_extra_opt': '',
        'docker_image': 'stevekieu/python3-cloud-ansible:2.9.9',
//This is will be appended to the list of script to run
        'extra_build_scripts': [],
//a map 'script_name': 'user_name' to instruct that script is run as the user.
//Default for add_user_scripts is root, and all other is normal user generated
//by the add_user_scripts
        'run_as_user': [:],
//This script will run not within docker container. Used to cleanup something if needed
        'outside_scripts': [:],
        'ssh_key_id': '',
        'ssh_key_file': '',
        'update_existing_user': '',
        ]

    def default_build_scripts = [
            'generate_add_user_script.sh',
            'generate_aws_environment.sh'
        ]

    def arg = default_arg + arg1
    def build_scripts = default_build_scripts + arg.extra_build_scripts

    def current_user = sh(returnStdout: true, script: "whoami").trim()
    def default_run_as_user = ['default_user': current_user, 'generate_add_user_script.sh': 'root']
    def run_as_user = arg.run_as_user + default_run_as_user

    // run build.sh at last
    build_scripts.add('build.sh')

    arg.docker_volume_opt = arg.docker_volume_opt + " " + arg.docker_default_volume_opt

    stage('run_build_script') {
        script {
            DOCKER_WORKSPACE = "${WORKSPACE}"
            //Generate add_user_scripts by default
            if (! fileExists("generate_add_user_script.sh")) {
                generate_add_user_script(arg.update_existing_user)
            }

            def run_build_scripts = { bsi, bso, docker_instance ->
                bsi.each { script_name ->
                    if (fileExists(script_name)) {
                        def _run_as_user = run_as_user[script_name]?:run_as_user.default_user
                        if (fileExists('.ssh-agent.groovy')) {
                            load '.ssh-agent.groovy'
                            sh "docker exec --user ${_run_as_user} -e SSH_AUTH_SOCK=$SSH_AUTH_SOCK -e SSH_AGENT_PID=$SSH_AGENT_PID  --workdir ${DOCKER_WORKSPACE} ${docker_instance.id} ./${script_name}"
                        }
                        else {
                            sh "docker exec --user ${_run_as_user} --workdir ${DOCKER_WORKSPACE} ${docker_instance.id} ./${script_name}"
                        }
                        sh "rm -f ${script_name}"
                    }
                    //else {
                    //    echo "${script_name} does not exist - skipping"
                    //}
                }//each inside
                bso.each { script_name ->
                    sh "./${script_name}"
                }//each outside
            }//end closure
            if (arg.ssh_key_id != '') {
                generate_prepare_ssh_agent_script()
                build_scripts = build_scripts.plus(1, 'run_ssh_agent.sh')
                withCredentials([sshUserPrivateKey(credentialsId: arg.ssh_key_id, keyFileVariable: 'SSH_KEY_FILE', passphraseVariable: 'SSH_PASS_PHRASE', usernameVariable: 'SSH_USER')]) {
                    docker.image(arg.docker_image).withRun("-u root ${arg.docker_volume_opt} ${arg.docker_net_opt} ${arg.docker_entrypoint_opt} ${arg.docker_extra_opt} -e SSH_KEY_FILE=$SSH_KEY_FILE -e SSH_PASS_PHRASE='${env.SSH_PASS_PHRASE}' -e SSH_USER=$SSH_USER -e ANSIBLE_USER=$SSH_USER", "${arg.docker_args_opt}") { c->
                    run_build_scripts(build_scripts, arg.outside_scripts, c)
                    }//docker env
                }//ssh-key-id
            } else if (arg.ssh_key_file != '') {
                generate_prepare_ssh_agent_script()
                build_scripts = build_scripts.plus(1, 'run_ssh_agent.sh')
                docker.image(arg.docker_image).withRun("-u root ${arg.docker_volume_opt} ${arg.docker_net_opt} ${arg.docker_entrypoint_opt} ${arg.docker_extra_opt} -e SSH_KEY_FILE=$SSH_KEY_FILE -e SSH_PASS_PHRASE='${env.SSH_PASS_PHRASE}' -e SSH_USER=$SSH_USER -e ANSIBLE_USER=$SSH_USER", "${arg.docker_args_opt}") { c->
                    run_build_scripts(build_scripts, arg.outside_scripts, c)
                    }//docker env
            }
            else {
                docker.image(arg.docker_image).withRun("-u root ${arg.docker_volume_opt} ${arg.docker_net_opt} ${arg.docker_entrypoint_opt} ${arg.docker_extra_opt}", "${arg.docker_args_opt}") { c->
                    run_build_scripts(build_scripts, arg.outside_scripts, c)
                }//docker env
            }
        }//script
    }//stage
}

def remove_file(file_name) {
    if (isUnix()) {
        sh "rm -f ${file_name} || true"
    }
    else {
        powershell """Remove-Item -Path '${file_name}'
        exit 0
        """
    }
}

//DONT USE THIS FOR PARAMETERISED JOB - Due to jenkins bug, see work around below from https://issues.jenkins-ci.org/browse/JENKINS-43758 but it is too ugly for me to use.
//The Multi branch build is fine as they dont have any parameters

def apply_maintenance_policy_per_branch() {

    if ((env.BRANCH != "") && ((env.ENV != "" ) || (env.APP_ENV != "")) ) {
        echo "This is parameterised job. Skipping all properties settings"
    } else {
        echo "BRANCH_NAME: ${env.BRANCH_NAME}"

        if ( env.BRANCH_NAME ==~ /release.*/ ) {
            echo "Process branch matches 'release'"
            properties([buildDiscarder(logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '', daysToKeepStr: '', numToKeepStr: ''))])
        }
        else if (env.BRANCH_NAME == "develop" || env.BRANCH_NAME == "master") {
            echo "Process branch matches 'develop'"
            properties([buildDiscarder(logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '7', daysToKeepStr: '', numToKeepStr: ''))])
        }
        else {
            echo "Process branch others than 'develop', 'release-XXX'"
            properties([buildDiscarder(logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '1', daysToKeepStr: '', numToKeepStr: ''))])
        }
    }
}

def save_build_data(build_data=[:]) {
    stage('save_build_data') {
        script {
            def default_data = [
                build_number: "${BUILD_NUMBER}",
                upstream_build_url: "${BUILD_URL}",
                upstream_job_name: "${JOB_NAME}",
                upstream_job_base_name: "${JOB_BASE_NAME}",
                ]

            if ( env.BRANCH_NAME ) {
                default_data = default_data + [ branch_name: "${BRANCH_NAME}"  ]
            }

            if ( ! env.GIT_REVISION ) {
               env.GIT_REVISION = sh(returnStdout: true, script: """
                    git rev-parse --short HEAD || echo 'No git revision found'"""
                ).trim()
            }

            default_data = default_data + [ git_revision: "${GIT_REVISION}" ]

            if ( env.BUILD_VERSION ) {
                default_data = default_data + [ artifact_version: "${BUILD_VERSION}" ]
            }

            def data = default_data + build_data
            remove_file('artifact_data.yml')
            writeYaml file: 'artifact_data.yml', data: data
            archiveArtifacts allowEmptyArchive: true, artifacts: 'artifact_data.yml', fingerprint: true, onlyIfSuccessful: true
        } //script
    }// Gather artifacts
}

def load_upstream_build_data() {
    // Take the env.UPSTREAM_BUILD_NUMBER (default to lasst success build), env.UPSTREAM_JOB_NAME it will load
    // the previously saved build data and load into the environment so other
    // steps can use it. Only a predefined set of vars exported by default. However ...
    // It also set the global ARTIFACT_DATA object which contains the whole parsed yaml file

    //Requires plugin `Copy Artifact Plugin`
    //This does not work anymore. Jenkins blacklisted the script security thus
    //u will get
    //org.jenkinsci.plugins.scriptsecurity.sandbox.RejectedAccessException: No
    //such field found when trying accessing the field data. Thus you better
    //copy artifacts in and parse the yml file using your own way in the
    //build.sh script. Ansible for example can read yaml var file directly.

    stage('load_upstream_build_data') {
        script {
            if ( ! env.UPSTREAM_BUILD_NUMBER ) {
                env.UPSTREAM_BUILD_NUMBER = 'LAST_SUCCESS_BUILD'
            }
            try {
                if (env.UPSTREAM_BUILD_NUMBER == 'LAST_SAVED_BUILD') {
                  copyArtifacts filter: 'artifact_data.yml', fingerprintArtifacts: true, flatten: true, projectName: "${UPSTREAM_JOB_NAME}", selector: latestSavedBuild()
                }
                else if (env.UPSTREAM_BUILD_NUMBER == 'LAST_SUCCESS_BUILD')  {
                    copyArtifacts filter: 'artifact_data.yml', fingerprintArtifacts: true, flatten: true, projectName: "${UPSTREAM_JOB_NAME}", selector: lastSuccessful()
                }
                else {
                  copyArtifacts filter: 'artifact_data.yml', fingerprintArtifacts: true, flatten: true, projectName: "${UPSTREAM_JOB_NAME}", selector: specific("${UPSTREAM_BUILD_NUMBER}")
                }//If
                // Parsing artifact data. TODO It wont work, see above comment.
                ARTIFACT_DATA = readYaml(file: 'artifact_data.yml')
                ARTIFACT_DATA.each { k, v ->
                    ARTIFACT_DATA[k] = v.replaceAll(/^"/,'').replaceAll(/"$/,'')
                }
                env.ARTIFACT_FILENAME = ARTIFACT_DATA.artifact_filename ?: (env.ARTIFACT_FILENAME ?: null)
                env.UPSTREAM_REVISION = ARTIFACT_DATA.git_revision ?: (env.UPSTREAM_REVISION ?: null)
                env.ARTIFACT_REVISION = ARTIFACT_DATA.artifact_revision ?: (ARTIFACT_DATA.git_revision ?: (env.ARTIFACT_REVISION ?: null))
                env.ARTIFACT_VERSION = ARTIFACT_DATA.artifact_version ?: (env.ARTIFACT_VERSION ?: null)
                env.UPSTREAM_BUILD_NUMBER = ARTIFACT_DATA.build_number ?: (env.UPSTREAM_BUILD_NUMBER ?: null)
                env.UPSTREAM_BRANCH_NAME = ARTIFACT_DATA.branch_name ?: (env.UPSTREAM_BRANCH_NAME ?: null)
                env.UPSTREAM_BUILD_URL = ARTIFACT_DATA.upstream_build_url ?: (env.UPSTREAM_BUILD_URL ?: null)
                env.UPSTREAM_JOB_NAME = ARTIFACT_DATA.upstream_job_name ?: (env.UPSTREAM_JOB_NAME ?: null)
                env.ARTIFACT_CLASS = ARTIFACT_DATA.artifact_class ?: (env.ARTIFACT_CLASS ?: null)
            } catch (Exception e) {
                echo "Unable to load_upstream_build_data - ${e}"
            }
        }//script
    }//stage
}
def validate_parameters(def args = [:]) {
    def UNSET_PARAM = "SET_ME"
    args.each {
        k, v ->
            echo "Validating ${k}"
            if (v.toString() == UNSET_PARAM) {
                echo "Parameter ${k} failed validation"
                currentBuild.displayName = 'Detected unset parameters'
                currentBuild.result = 'ABORTED'
                error 'Detected unset parameters (potentially unexposed parameters) - stopping current build'
            }
    }
}
return this
